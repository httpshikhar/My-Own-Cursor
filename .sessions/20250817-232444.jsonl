{"role": "system", "content": "\nYou are an AI Software Engineer working inside an AI-powered IDE.\n\nYour job is to take high-level goals from the user (e.g., \"Build a CLI todo app\") and fully complete them using the available tools.\n\nYou are not just a code generator ‚Äî you think, plan, verify, fix, and iterate to accomplish the goal end-to-end.\n\n## Responsibilities\n\n1. **Understand the Goal**  \n   Carefully read the user's message to understand the desired outcome.\n\n2. **Plan the Task**  \n   Use the `plan_task` tool to break the goal into smaller actionable steps (like \"write main.py\", \"define CLI\", etc.)\n\n3. **Generate Project Structure**  \n   If a project folder needs to be created with multiple files, use the `generate_project_structure` tool.\n\n4. **Execute Step-by-Step**  \n   For individual tasks, use `write_file`, `read_file`, `edit_file`, `run_code_file`, and `run_shell_command`.\n\n5. **Verify and Self-Debug**  \n   Always run generated code; debug and iterate on failures.\n\n6. **Stay Autonomous**  \n   Don‚Äôt ask for permission at every step; only ask if user input is required.\n\n7. **Suggest the Next Move**  \n   After each step, clearly suggest the next logical move to complete the goal.\n", "ts": 1755453284.0190187}
{"role": "tool", "content": "=== main.py (text) ===\n\nimport os\nimport json\nimport argparse\nfrom dotenv import load_dotenv\nfrom openai import AzureOpenAI\nfrom openai import APIConnectionError\nimport httpx\nfrom tool_registry import get_available_tools\nfrom chat_memory import ChatMemory\nfrom tools.file_tools import *\nfrom tools.shell_tool import *\nfrom tools.code_runner import run_code_file, run_code_file_tool\nfrom tools.planner_tool import plan_task, plan_task_tool\nfrom tools.project_generator import generate_project_structure, generate_project_structure_tool\n\n# Rich terminal UI\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.markdown import Markdown\nfrom rich.live import Live\nfrom rich.syntax import Syntax\nfrom rich import box\nimport difflib\nfrom prompt_toolkit.shortcuts import radiolist_dialog, input_dialog\nfrom prompt_toolkit import PromptSession\nfrom prompt_toolkit.completion import Completer, Completion\nfrom prompt_toolkit.formatted_text import HTML\nfrom prompt_toolkit.patch_stdout import patch_stdout\n\n# Load secrets\nload_dotenv()\nAZURE_OAI_ENDPOINT = os.getenv(\"AZURE_OAI_ENDPOINT\")\nAZURE_OAI_KEY = os.getenv(\"AZURE_OAI_KEY\")\nAZURE_OAI_DEPLOYMENT = os.getenv(\"AZURE_OAI_DEPLOYMENT\")\n\n# Optional TLS/Proxy configuration for corporate environments\nAZURE_OAI_CA_BUNDLE = os.getenv(\"AZURE_OAI_CA_BUNDLE\")  # path to custom CA bundle (.pem)\nAZURE_OAI_INSECURE = os.getenv(\"AZURE_OAI_INSECURE\", \"false\").strip().lower() in {\"1\", \"true\", \"yes\", \"y\"}\n\n\ndef _build_http_client() -> httpx.Client | None:\n    \"\"\"Create an httpx client with optional custom TLS verification.\n\n    - If AZURE_OAI_CA_BUNDLE points to a file, use it to verify TLS.\n    - If AZURE_OAI_INSECURE=true, disable TLS verification (NOT recommended).\n    - Otherwise, return None to use library defaults.\n    \"\"\"\n    try:\n        if AZURE_OAI_CA_BUNDLE and os.path.exists(AZURE_OAI_CA_BUNDLE):\n            # Also set common envs so any subprocesses use the same CA\n            os.environ.setdefault(\"REQUESTS_CA_BUNDLE\", AZURE_OAI_CA_BUNDLE)\n            os.environ.setdefault(\"SSL_CERT_FILE\", AZURE_OAI_CA_BUNDLE)\n            return httpx.Client(verify=AZURE_OAI_CA_BUNDLE)\n        if AZURE_OAI_INSECURE:\n            return httpx.Client(verify=False)\n    except Exception:\n        # Fall back to default client behavior if any issue occurs\n        return None\n    return None\n\n# Init client and tools\n_http_client = _build_http_client()\nclient = (\n    AzureOpenAI(\n        azure_endpoint=AZURE_OAI_ENDPOINT,\n        api_key=AZURE_OAI_KEY,\n        api_version=\"2024-02-15-preview\",\n        http_client=_http_client,\n    )\n    if _http_client is not None\n    else AzureOpenAI(\n        azure_endpoint=AZURE_OAI_ENDPOINT,\n        api_key=AZURE_OAI_KEY,\n        api_version=\"2024-02-15-preview\",\n    )\n)\ntools = [\n    write_file_tool,\n    write_files_tool,\n    shell_tool,\n    edit_file_tool,\n    read_file_tool,\n    read_files_tool,\n    run_python_file_tool,\n    run_code_file_tool,\n    plan_task_tool,\n    generate_project_structure_tool,\n]\n\nhistory: ChatMemory | None = None\nconsole = Console()\n\n\ndef _panel_for(role: str, content: str) -> Panel:\n    role_title = {\n        \"system\": \"System\",\n        \"user\": \"You\",\n        \"assistant\": \"Assistant\",\n        \"tool\": \"Tool\",\n    }.get(role, role.capitalize())\n\n    border = {\n        \"system\": \"grey50\",\n        \"user\": \"cyan\",\n        \"assistant\": \"magenta\",\n        \"tool\": \"yellow\",\n    }.get(role, \"white\")\n\n    # Render content as Markdown to support code blocks and formatting\n    body = Markdown(content or \"(empty)\")\n    return Panel(\n        body,\n        title=f\"[bold]{role_title}[/bold]\",\n        border_style=border,\n        box=box.ROUNDED,\n        expand=True,\n    )\n\n\ndef _print_header():\n    console.rule(\"[bold cyan]AI IDE ‚Äî Agent REPL[/bold cyan]\")\n    console.print(\n        \"Use 'exit' or 'quit' to leave. Messages render as Markdown with code blocks.\",\n        style=\"dim\",\n    )\n    console.print()\n\n\ndef _print_session_info():\n    if history is None:\n        return\n    msgs = history.get()\n    total = len(msgs)\n    title = f\"Session: {history.session_id} ({total} messages)\"\n    # Show last few non-tool messages for quick recall\n    preview = []\n    shown = 0\n    for m in reversed(msgs):\n        if m.get(\"role\") in {\"tool\"}:\n            continue\n        preview.append(f\"- {m.get('role')}: {str(m.get('content'))[:120].replace('\\n',' ')}\")\n        shown += 1\n        if shown >= 5:\n            break\n    text = \"\\n\".join(reversed(preview)) if preview else \"(no prior messages)\"\n    console.print(Panel(text, title=title, border_style=\"cyan\", box=box.ROUNDED))\n\n\ndef _list_sessions(max_items: int = 50) -> list[str]:\n    if history is None:\n        return []\n    try:\n        files = [f for f in os.listdir(history.storage_dir) if f.endswith(\".jsonl\")]\n        ids = [os.path.splitext(f)[0] for f in files]\n        return sorted(ids, reverse=True)[:max_items]\n    except Exception:\n        return []\n\n\ndef _start_new_session(session_id: str | None = None):\n    global history\n    sessions_dir = history.storage_dir if history else \".sessions\"\n    history = ChatMemory.new_session(session_id=session_id, storage_dir=sessions_dir)\n    console.print(Panel(f\"Started new session: {history.session_id}\", title=\"Session\", border_style=\"cyan\", box=box.ROUNDED))\n    # Add system prompt to fresh session\n    history.add(\"system\", SYSTEM_PROMPT)\n\n\ndef _switch_session(session_id: str):\n    global history\n    if history is None:\n        return\n    sessions_dir = history.storage_dir\n    history = ChatMemory.load(session_id, storage_dir=sessions_dir)\n    console.print(Panel(f\"Switched to session: {history.session_id}\", title=\"Session\", border_style=\"cyan\", box=box.ROUNDED))\n    _print_session_info()\n\n\ndef _show_context(n: int = 10):\n    if history is None:\n        return\n    msgs = [m for m in history.get() if m.get(\"role\") != \"tool\"]\n    tail = msgs[-n:]\n    lines = [f\"- {m['role']}: {str(m['content'])[:200].replace('\\n',' ')}\" for m in tail]\n    console.print(Panel(\"\\n\".join(lines) if lines else \"(empty)\", title=f\"Last {n} messages\", border_style=\"cyan\", box=box.ROUNDED))\n\n\ndef _handle_slash_command(user_input: str) -> bool:\n    \"\"\"Return True if handled. Implements: /help, /sessions, /session <id>, /new [id], /save, /context [n],\n    /read <path>, /runpy <path> [inputs...], /run <path>, /shell <cmd...>, /plan <goal...>\n    \"\"\"\n    if not user_input.startswith(\"/\"):\n        return False\n\n    # If only '/', do nothing (menu is shown inline via completer). Do not send to LLM.\n    if user_input.strip() == \"/\":\n        return True\n\n    parts = user_input.strip().split()\n    cmd = parts[0].lower()\n    args = parts[1:]\n\n    # Commands\n    if cmd in {\"/help\", \"/?\"}:\n        help_text = (\n            \"Commands:\\n\"\n            \"- /                 Open interactive command palette\\n\"\n            \"- /new [id]            Start a new chat session (optional custom id)\\n\"\n            \"- /sessions            List available session IDs\\n\"\n            \"- /session [id]        Switch to an existing session (picker if omitted)\\n\"\n            \"- /save                Flush in-memory messages to disk\\n\"\n            \"- /context [n]         Show last n messages (default 10)\\n\"\n            \"- /runpy <path> [... ] Run a Python file with optional inputs\\n\"\n            \"- /run <path>          Run a code file (.py/.sh/.cpp)\\n\"\n            \"- /plan <goal>         Invoke planner tool on a goal\\n\"\n            \"\\nAttach context with @paths (files/images/folders). Example: 'Summarize @README.md @src/'.\\n\"\n        )\n        console.print(Panel(help_text, title=\"Help\", border_style=\"green\", box=box.ROUNDED))\n        return True\n\n    if cmd == \"/sessions\":\n        ids = _list_sessions()\n        cur = history.session_id if history else \"-\"\n        lines = [f\"* {sid} {'(current)' if sid == cur else ''}\" for sid in ids] or [\"(none)\"]\n        console.print(Panel(\"\\n\".join(lines), title=\"Sessions\", border_style=\"cyan\", box=box.ROUNDED))\n        return True\n\n    if cmd == \"/new\":\n        sid = args[0] if args else None\n        _start_new_session(sid)\n        return True\n\n    if cmd == \"/session\":\n        if not args:\n            ids = _list_sessions()\n            if not ids:\n                console.print(Panel(\"No sessions found.\", title=\"Sessions\", border_style=\"red\", box=box.ROUNDED))\n                return True\n            chosen = radiolist_dialog(\n                title=\"Switch Session\",\n                text=\"Choose a session\",\n                values=[(sid, sid) for sid in ids],\n            ).run()\n            if chosen:\n                _switch_session(chosen)\n            return True\n        _switch_session(args[0])\n        return True\n\n    if cmd == \"/save\":\n        if history:\n            history.save()\n            console.print(Panel(\"Session saved.\", title=\"Session\", border_style=\"green\", box=box.ROUNDED))\n        return True\n\n    if cmd == \"/context\":\n        n = 10\n        if args:\n            try:\n                n = int(args[0])\n            except Exception:\n                pass\n        _show_context(n)\n        return True\n\n    # /read removed (use @path context instead)\n\n    if cmd == \"/runpy\":\n        if not args:\n            console.print(Panel(\"Usage: /runpy <path> [inputs ...]\", title=\"Error\", border_style=\"red\", box=box.ROUNDED))\n            return True\n        path = args[0]\n        inputs = args[1:] if len(args) > 1 else None\n        res = run_python_file(path=path, inputs=inputs)\n        console.print(Panel(res, title=f\"Run Python: {path}\", border_style=\"yellow\", box=box.ROUNDED))\n        return True\n\n    if cmd == \"/run\":\n        if not args:\n            console.print(Panel(\"Usage: /run <path>\", title=\"Error\", border_style=\"red\", box=box.ROUNDED))\n            return True\n        path = args[0]\n        res = run_code_file(path=path)\n        console.print(Panel(res, title=f\"Run: {path}\", border_style=\"yellow\", box=box.ROUNDED))\n        return True\n\n    # /shell removed\n\n    if cmd == \"/plan\":\n        if not args:\n            console.print(Panel(\"Usage: /plan <goal>\", title=\"Error\", border_style=\"red\", box=box.ROUNDED))\n            return True\n        goal = \" \".join(args)\n        res = plan_task(goal)\n        console.print(Panel(res, title=\"Planner\", border_style=\"green\", box=box.ROUNDED))\n        return True\n\n    console.print(Panel(f\"Unknown command: {cmd}\", title=\"Error\", border_style=\"red\", box=box.ROUNDED))\n    return True\n\n\ndef _open_command_palette():\n    \"\"\"Interactive menu for slash commands with arrow-key navigation and simple sub-dialogs.\"\"\"\n    items = [\n        (\"/new\", \"Start new session\"),\n        (\"/sessions\", \"List sessions\"),\n        (\"/session\", \"Switch session\"),\n        (\"/save\", \"Save session to disk\"),\n        (\"/context\", \"Show last N messages\"),\n        (\"/runpy\", \"Run a Python file with inputs\"),\n        (\"/run\", \"Run a code file (.py/.sh/.cpp)\"),\n        (\"/plan\", \"Plan a goal\"),\n        (\"/help\", \"Show help\"),\n    ]\n\n    result = radiolist_dialog(\n        title=\"Command Palette\",\n        text=\"Select a command\",\n        values=[(k, f\"{k} ‚Äì {label}\") for k, label in items],\n    ).run()\n\n    if not result:\n        return\n\n    # Sub-dialogs / options per command\n    if result == \"/new\":\n        sid = input_dialog(title=\"New Session\", text=\"Optional session id (leave blank for auto):\").run()\n        _start_new_session(sid if sid else None)\n        return\n\n    if result == \"/sessions\":\n        ids = _list_sessions()\n        lines = [f\"* {sid} {'(current)' if history and sid == history.session_id else ''}\" for sid in ids] or [\"(none)\"]\n        console.print(Panel(\"\\n\".join(lines), title=\"Sessions\", border_style=\"cyan\", box=box.ROUNDED))\n        return\n\n    if result == \"/session\":\n        ids = _list_sessions()\n        if not ids:\n            console.print(Panel(\"No sessions found.\", title=\"Sessions\", border_style=\"red\", box=box.ROUNDED))\n            return\n        chosen = radiolist_dialog(\n            title=\"Switch Session\",\n            text=\"Choose a session\",\n            values=[(sid, sid) for sid in ids],\n        ).run()\n        if chosen:\n            _switch_session(chosen)\n        return\n\n    if result == \"/save\":\n        if history:\n            history.save()\n            console.print(Panel(\"Session saved.\", title=\"Session\", border_style=\"green\", box=box.ROUNDED))\n        return\n\n    if result == \"/context\":\n        n_str = input_dialog(title=\"Context\", text=\"How many messages to show? (default 10)\").run()\n        try:\n            n = int(n_str) if n_str else 10\n        except Exception:\n            n = 10\n        _show_context(n)\n        return\n\n    # /read removed\n\n    if result == \"/runpy\":\n        path = input_dialog(title=\"Run Python\", text=\"Path to Python file:\").run()\n        if not path:\n            return\n        inputs_raw = input_dialog(title=\"Inputs\", text=\"Optional inputs (one line; separate multiple with |):\").run()\n        inputs = [s.strip() for s in inputs_raw.split(\"|\")] if inputs_raw else None\n        res = run_python_file(path=path, inputs=inputs)\n        console.print(Panel(res, title=f\"Run Python: {path}\", border_style=\"yellow\", box=box.ROUNDED))\n        return\n\n    if result == \"/run\":\n        path = input_dialog(title=\"Run Code\", text=\"Path to file (.py/.sh/.cpp):\").run()\n        if path:\n            res = run_code_file(path=path)\n            console.print(Panel(res, title=f\"Run: {path}\", border_style=\"yellow\", box=box.ROUNDED))\n        return\n\n    # /shell removed\n\n    if result == \"/plan\":\n        goal = input_dialog(title=\"Planner\", text=\"What is your goal?\").run()\n        if goal:\n            res = plan_task(goal)\n            console.print(Panel(res, title=\"Planner\", border_style=\"green\", box=box.ROUNDED))\n        return\n\n    if result == \"/help\":\n        _handle_slash_command(\"/help\")\n        return\n\n\n# ----- Slash command dynamic completer -----\nCOMMAND_SPECS: list[tuple[str, str]] = [\n    (\"/new\", \"Start new session\"),\n    (\"/sessions\", \"List sessions\"),\n    (\"/session\", \"Switch session\"),\n    (\"/save\", \"Save session to disk\"),\n    (\"/context\", \"Show last N messages\"),\n    (\"/runpy\", \"Run a Python file with inputs\"),\n    (\"/run\", \"Run a code file (.py/.sh/.cpp)\"),\n    (\"/plan\", \"Plan a goal\"),\n    (\"/help\", \"Show help\"),\n]\n\n\nclass SlashCompleter(Completer):\n    def get_completions(self, document, complete_event):\n        text = document.text_before_cursor\n        # 1) Slash command completion only when the entire input starts with '/'\n        if text.startswith('/'):\n            word = text\n            for cmd, desc in COMMAND_SPECS:\n                if cmd.startswith(word):\n                    display = f\"{cmd} ‚Äî {desc}\"\n                    yield Completion(cmd, start_position=-len(word), display=display, display_meta=desc)\n\n        # 2) Dynamic @-path completion: complete the current token if it begins with '@'\n        # Works anywhere in the line, not just at the start\n        # Strategy: identify the last whitespace-delimited token before cursor\n        # If it starts with '@', treat the remainder as a filesystem path prefix\n        # and listdir on the appropriate base directory.\n        # Example inputs:\n        #   \"Summarize @src/ma\" -> completes files/dirs under ./src starting with 'ma'\n        #   \"@\" -> lists entries in cwd\n        #   \"See @~/proj\" -> expands ~ and lists under that dir\n        before = text\n        # Find the current token (after last whitespace)\n        last_space = max(before.rfind(' '), before.rfind('\\t'))\n        token = before[last_space + 1:] if last_space != -1 else before\n        if token.startswith('@') and len(token) >= 1:\n            raw_path = token[1:]\n            # Handle optional surrounding quotes while typing (basic handling)\n            if (raw_path.startswith(\"'\") and not raw_path.endswith(\"'\")) or (\n                raw_path.startswith('\"') and not raw_path.endswith('\"')\n            ):\n                # Don't attempt to complete until closing quote; fall back to no results\n                return\n\n            # Strip balanced quotes\n            if (raw_path.startswith(\"'\") and raw_path.endswith(\"'\")) or (\n                raw_path.startswith('\"') and raw_path.endswith('\"')\n            ):\n                raw_path = raw_path[1:-1]\n\n            # Expand ~ and environment variables\n            expanded = os.path.expanduser(os.path.expandvars(raw_path)) if raw_path else ''\n\n            # Determine base directory and prefix to match\n            if expanded and (os.sep in expanded or (os.altsep and os.altsep in expanded)):\n                base_dir = os.path.dirname(expanded) or os.curdir\n                prefix = os.path.basename(expanded)\n            else:\n                base_dir = expanded or os.curdir\n                prefix = ''\n\n            try:\n                entries = []\n                if os.path.isdir(base_dir):\n                    for name in os.listdir(base_dir):\n                        if prefix and not name.startswith(prefix):\n                            continue\n                        full_path = os.path.join(base_dir, name)\n                        is_dir = os.path.isdir(full_path)\n                        # Build the suggestion path relative to what user typed\n                        # Reconstruct suggestion keeping the original raw prefix\n                        # If user typed something like \"@src/ma\", we suggest \"@src/main.py\" etc.\n                        if expanded:\n                            # Compute path segment to append after the base_dir\n                            after_base = name\n                            # If base_dir is '.' but user provided some raw_path, keep that raw parent\n                            if os.path.normpath(base_dir) != os.curdir:\n                                suggested_raw = os.path.join(raw_path[: max(0, len(raw_path) - len(prefix))], after_base)\n                            else:\n                                suggested_raw = os.path.join(raw_path[: max(0, len(raw_path) - len(prefix))], after_base)\n                        else:\n                            suggested_raw = name\n\n                        # Append path separator for directories to ease further navigation\n                        display_name = suggested_raw + (os.sep if is_dir else '')\n                        completion_text = '@' + display_name\n                        meta = 'dir' if is_dir else 'file'\n                        # Replace only the current token\n                        yield Completion(\n                            completion_text,\n                            start_position=-len(token),\n                            display=display_name,\n                            display_meta=meta,\n                        )\n                # If base_dir doesn't exist, yield nothing\n            except Exception:\n                # Silently ignore completion errors\n                return\n\n\ndef _bottom_toolbar():\n    return HTML(\"<b>Tips:</b> Type '/' to see commands ‚Ä¢ Use ‚Üë/‚Üì to navigate ‚Ä¢ Enter to run ‚Ä¢ 'exit' to quit\")\n\n\n# ----- @-context attachment helpers -----\nTEXT_EXTS = {\n    \".py\", \".txt\", \".md\", \".json\", \".yaml\", \".yml\", \".toml\", \".ini\", \".cfg\",\n    \".xml\", \".html\", \".css\", \".js\", \".ts\", \".tsx\", \".jsx\", \".csv\", \".env\",\n}\n\n\ndef _is_text_file(path: str) -> bool:\n    _, ext = os.path.splitext(path)\n    return ext.lower() in TEXT_EXTS\n\n\ndef _extract_at_paths(text: str) -> tuple[str, list[str]]:\n    parts = text.split()\n    paths: list[str] = []\n    cleaned_parts: list[str] = []\n    for p in parts:\n        if p.startswith(\"@\") and len(p) > 1:\n            raw = p[1:]\n            # strip surrounding quotes if present\n            if (raw.startswith(\"'\") and raw.endswith(\"'\")) or (raw.startswith('\"') and raw.endswith('\"')):\n                raw = raw[1:-1]\n            paths.append(raw)\n        else:\n            cleaned_parts.append(p)\n    cleaned = \" \".join(cleaned_parts)\n    return cleaned, paths\n\n\ndef _expand_paths(paths: list[str], max_files: int = 50) -> list[str]:\n    files: list[str] = []\n    for p in paths:\n        if not p:\n            continue\n        if os.path.isdir(p):\n            for root, _, fnames in os.walk(p):\n                for fname in fnames:\n                    fp = os.path.join(root, fname)\n                    files.append(fp)\n                    if len(files) >= max_files:\n                        return files\n        elif os.path.isfile(p):\n            files.append(p)\n    return files\n\n\ndef _build_context_tool_message(files: list[str], char_limit: int = 80000) -> dict:\n    lines: list[str] = []\n    used = 0\n    for fpath in files:\n        try:\n            if _is_text_file(fpath):\n                with open(fpath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n                    content = f.read()\n                header = f\"=== {fpath} (text) ===\"\n                budget = max(0, char_limit - used - len(header) - 1)\n                snippet = content if len(content) <= budget else content[:budget] + \"\\n‚Ä¶[truncated]\"\n                lines.append(header)\n                lines.append(snippet)\n                used += len(header) + 1 + len(snippet)\n                if used >= char_limit:\n                    lines.append(\"‚Ä¶[context size limit reached]\")\n                    break\n            else:\n                size = os.path.getsize(fpath)\n                lines.append(f\"=== {fpath} (binary {size} bytes) ===\")\n        except Exception as e:\n            lines.append(f\"=== {fpath} (error: {e}) ===\")\n    content = \"\\n\\n\".join(lines) if lines else \"(no context)\"\n    return {\"role\": \"tool\", \"name\": \"attach_context\", \"content\": content}\n\n\ndef log_created_files(paths: list[str], created_accumulator: list[str] | None = None):\n    if not paths:\n        return\n    message = \"\\n\".join(paths)\n    console.print(Panel(message, title=\"Created files\", border_style=\"green\", box=box.ROUNDED))\n    if created_accumulator is not None:\n        created_accumulator.extend(paths)\n\n\ndef log_edited_file(path: str, mode: str, edited_accumulator: list[tuple[str, str]] | None = None):\n    console.print(Panel(f\"{path} (mode: {mode})\", title=\"Edited file\", border_style=\"blue\", box=box.ROUNDED))\n    if edited_accumulator is not None:\n        edited_accumulator.append((path, mode))\n\n\ndef log_command_run(command: str, commands_accumulator: list[str] | None = None):\n    console.print(Panel(f\"$ {command}\", title=\"Ran command\", border_style=\"cyan\", box=box.ROUNDED))\n    if commands_accumulator is not None:\n        commands_accumulator.append(command)\n\n\ndef _read_file_text(path: str) -> str | None:\n    try:\n        with open(path, \"r\", encoding=\"utf-8\") as f:\n            return f.read()\n    except Exception:\n        return None\n\n\ndef render_edit_diff(path: str, before_text: str | None, after_text: str | None):\n    if before_text is None or after_text is None:\n        return\n    diff_lines = list(\n        difflib.unified_diff(\n            before_text.splitlines(),\n            after_text.splitlines(),\n            fromfile=f\"a/{path}\",\n            tofile=f\"b/{path}\",\n            lineterm=\"\",\n        )\n    )\n    if not diff_lines:\n        return\n    diff_text = \"\\n\".join(diff_lines)\n    console.print(\n        Panel(\n            Syntax(diff_text, \"diff\", theme=\"ansi_dark\"),\n            title=f\"Changes: {path}\",\n            border_style=\"blue\",\n            box=box.ROUNDED,\n        )\n    )\n\n\ndef _render_summary(created_files: list[str], edited_files: list[tuple[str, str]], ran_commands: list[str], assistant_notes: str | None):\n    parts: list[str] = []\n\n    # Changes\n    parts.append(\"### Changes made\")\n    if created_files:\n        parts.append(\"- Created:\")\n        parts.extend([f\"  - {p}\" for p in created_files])\n    if edited_files:\n        parts.append(\"- Edited:\")\n        parts.extend([f\"  - {p} (mode: {m})\" for p, m in edited_files])\n    if not created_files and not edited_files:\n        parts.append(\"- No file changes recorded.\")\n\n    # Commands\n    parts.append(\"\\n### Commands run\")\n    if ran_commands:\n        parts.extend([f\"- $ {c}\" for c in ran_commands])\n    else:\n        parts.append(\"- None\")\n\n    # How to run\n    parts.append(\"\\n### How to run\")\n    parts.append(\"- Activate env: `source Python/.venv/bin/activate`\")\n    parts.append(\"- Start agent UI: `python \\\"Python/main.py\\\"`\")\n    py_created = [p for p in created_files if p.endswith(\".py\")]\n    if py_created:\n        # Suggest running notable python files (e.g. main.py) directly\n        notable = [p for p in py_created if os.path.basename(p) in {\"main.py\", \"app.py\"}] or py_created[:2]\n        for path in notable:\n            parts.append(f\"- Run script: `python \\\"{path}\\\"`\")\n\n    # Suggestions / next steps\n    parts.append(\"\\n### Suggestions\")\n    if assistant_notes:\n        parts.append(\"- Review assistant notes below for next actions.\")\n    parts.append(\"- Review created/edited files and run them as needed.\")\n    parts.append(\"- Add tests and a README if missing.\")\n    parts.append(\"- Commit your changes when satisfied.\")\n\n    summary_md = \"\\n\".join(parts)\n    console.print(Panel(Markdown(summary_md), title=\"Session summary\", border_style=\"magenta\", box=box.ROUNDED))\n    if assistant_notes:\n        console.print(Panel(Markdown(assistant_notes), title=\"Assistant notes\", border_style=\"magenta\", box=box.ROUNDED))\n\n\n# ===== Multi-agent mode support =====\n# Safe wrapper around chat.completions.create to handle TLS/proxy issues\ndef _chat_create(*, messages, tools=None, tool_choice=None, model: str = AZURE_OAI_DEPLOYMENT):\n    try:\n        return client.chat.completions.create(\n            model=model,\n            messages=messages,\n            tools=tools,\n            tool_choice=tool_choice,\n        )\n    except APIConnectionError as err:\n        help_text = (\n            \"Connection to Azure OpenAI failed. If you are behind a proxy or corporate CA, set \"\n            \"`AZURE_OAI_CA_BUNDLE` to your PEM file, or set `AZURE_OAI_INSECURE=true` to skip verification (not recommended).\\n\"\n            \"Alternatives: set `REQUESTS_CA_BUNDLE` or `SSL_CERT_FILE` env vars.\\n\"\n            f\"Original error: {err}\"\n        )\n        console.print(Panel(help_text, title=\"Connection error\", border_style=\"red\", box=box.ROUNDED))\n        return None\n    except Exception as err:\n        console.print(Panel(str(err), title=\"Unexpected error\", border_style=\"red\", box=box.ROUNDED))\n        return None\n\n\ndef _chat_stream(\n    *,\n    messages,\n    tools=None,\n    tool_choice=None,\n    model: str = AZURE_OAI_DEPLOYMENT,\n    panel_title: str | None = None,\n    panel_border_style: str | None = None,\n):\n    \"\"\"Stream assistant output with a spinner. Returns (response, rendered_bool) or (None, False) on error.\n\n    rendered_bool indicates whether we already rendered assistant content (so caller should not re-print it).\n    \"\"\"\n    try:\n        # Establish the stream\n        stream_ctx = client.chat.completions.stream(\n            model=model,\n            messages=messages,\n            tools=tools,\n            tool_choice=tool_choice,\n        )\n        accumulated_text = \"\"\n        rendered_any_content = False\n        placeholder = \"‚Ä¶\"\n        with stream_ctx as stream:\n            # Keep spinner visible until first content token arrives (or completion ends)\n            with console.status(\"Assistant is thinking...\", spinner=\"dots\"):\n                for event in stream:\n                    event_type = getattr(event, \"type\", None)\n                    if event_type == \"message.delta\":\n                        delta = getattr(event, \"delta\", None)\n                        if delta is None:\n                            continue\n                        content = getattr(delta, \"content\", None)\n                        if isinstance(content, str):\n                            accumulated_text += content\n                            rendered_any_content = rendered_any_content or bool(content)\n                        elif isinstance(content, list):\n                            for part in content:\n                                text = \"\"\n                                if isinstance(part, dict):\n                                    text = part.get(\"text\") or part.get(\"content\") or \"\"\n                                elif isinstance(part, str):\n                                    text = part\n                                accumulated_text += text\n                                rendered_any_content = rendered_any_content or bool(text)\n                        # We got first visible content: break to start live panel\n                        if rendered_any_content:\n                            break\n                    elif event_type == \"message.completed\":\n                        # No content is expected; stop spinner and proceed to finalize\n                        break\n                    else:\n                        # Ignore other event types while waiting\n                        pass\n\n            # Start live panel (spinner has just stopped)\n            with Live(\n                Panel(\n                    Markdown(accumulated_text or placeholder),\n                    title=(panel_title or \"Assistant\"),\n                    border_style=(panel_border_style or \"magenta\"),\n                    box=box.ROUNDED,\n                ),\n                refresh_per_second=12,\n                console=console,\n                transient=True,\n            ) as live:\n                for event in stream:\n                    event_type = getattr(event, \"type\", None)\n                    if event_type == \"message.delta\":\n                        delta = getattr(event, \"delta\", None)\n                        if delta is None:\n                            continue\n                        content = getattr(delta, \"content\", None)\n                        if isinstance(content, str):\n                            accumulated_text += content\n                            rendered_any_content = rendered_any_content or bool(content)\n                        elif isinstance(content, list):\n                            for part in content:\n                                text = \"\"\n                                if isinstance(part, dict):\n                                    text = part.get(\"text\") or part.get(\"content\") or \"\"\n                                elif isinstance(part, str):\n                                    text = part\n                                accumulated_text += text\n                                rendered_any_content = rendered_any_content or bool(text)\n                        live.update(\n                            Panel(\n                                Markdown(accumulated_text or placeholder),\n                                title=(panel_title or \"Assistant\"),\n                                border_style=(panel_border_style or \"magenta\"),\n                                box=box.ROUNDED,\n                            )\n                        )\n                    elif event_type == \"tool_calls.delta\":\n                        # Not user-facing; ignore\n                        pass\n                    elif event_type == \"message.completed\":\n                        # Final message assembled\n                        pass\n                final_response = stream.get_final_response()\n\n        # After the live context exits, persist output only if we actually rendered content\n        if rendered_any_content:\n            console.print(\n                Panel(\n                    Markdown(accumulated_text),\n                    title=(panel_title or \"Assistant\"),\n                    border_style=(panel_border_style or \"magenta\"),\n                    box=box.ROUNDED,\n                )\n            )\n        return final_response, rendered_any_content\n    except APIConnectionError as err:\n        help_text = (\n            \"Connection to Azure OpenAI failed. If you are behind a proxy or corporate CA, set \"\n            \"`AZURE_OAI_CA_BUNDLE` to your PEM file, or set `AZURE_OAI_INSECURE=true` to skip verification (not recommended).\\n\"\n            \"Alternatives: set `REQUESTS_CA_BUNDLE` or `SSL_CERT_FILE` env vars.\\n\"\n            f\"Original error: {err}\"\n        )\n        console.print(Panel(help_text, title=\"Connection error\", border_style=\"red\", box=box.ROUNDED))\n        return None, False\n    except Exception:\n        # If streaming is not supported or any error occurs, fall back to non-streaming\n        response = _chat_create(messages=messages, tools=tools, tool_choice=tool_choice, model=model)\n        return response, False\n# Prompts for different specialized agents\nPLANNER_PROMPT = (\n    \"You are the Planner agent. Your job is to break the user's goal into a concise, actionable plan of 3-10 steps focused on coding tasks. \"\n    \"Prefer concrete file operations and commands. Do not execute, only plan.\"\n)\n\nCODER_PROMPT = (\n    \"You are the Coder agent. Your job is to implement the plan end-to-end using available tools. \"\n    \"Favor creating files, editing code, running code, and shell commands when needed. \"\n    \"Think step-by-step and verify outputs. Keep going until the goal is complete.\"\n)\n\nREVIEWER_PROMPT = (\n    \"You are the Reviewer agent. Review the recent code changes for correctness, style, and potential issues. \"\n    \"Suggest improvements and, if safe and unambiguous, apply small fixes using edit tools. Keep feedback concise and practical.\"\n)\n\n\ndef run_multi_agent_session(user_goal: str):\n    \"\"\"Run a Planner -> Coder (with tools) -> Reviewer (optional fixes) pipeline.\"\"\"\n    # ---------- Planner ----------\n    planner_messages = [\n        {\"role\": \"system\", \"content\": PLANNER_PROMPT},\n        {\"role\": \"user\", \"content\": f\"Plan the following goal:\\n{user_goal}\"},\n    ]\n    planner_response, rendered_stream = _chat_stream(\n        messages=planner_messages,\n        model=AZURE_OAI_DEPLOYMENT,\n        panel_title=\"Planner\",\n        panel_border_style=\"green\",\n    )\n    if planner_response is None:\n        return\n    planner_plan = planner_response.choices[0].message.content or \"(No plan produced)\"\n    if not rendered_stream:\n        console.print(Panel(Markdown(planner_plan), title=\"Planner\", border_style=\"green\", box=box.ROUNDED))\n\n    # ---------- Coder (tool-enabled loop) ----------\n    created_files_session: list[str] = []\n    edited_files_session: list[tuple[str, str]] = []\n    commands_session: list[str] = []\n    final_notes: str | None = None\n\n    coder_history = [\n        {\"role\": \"system\", \"content\": CODER_PROMPT},\n        {\"role\": \"user\", \"content\": f\"Goal:\\n{user_goal}\"},\n        {\"role\": \"assistant\", \"content\": f\"Plan:\\n{planner_plan}\"},\n    ]\n\n    for _ in range(15):\n        response, rendered_stream = _chat_stream(\n            messages=coder_history,\n            tools=tools,\n            tool_choice=\"auto\",\n            model=AZURE_OAI_DEPLOYMENT,\n            panel_title=\"Coder\",\n            panel_border_style=\"magenta\",\n        )\n        if response is None:\n            console.print(\"[bold red]Stopping due to connection error.[/bold red]\")\n            break\n        reply = response.choices[0].message\n        tool_calls = reply.tool_calls\n\n        if not tool_calls:\n            final_content = reply.content or \"(No reply)\"\n            final_notes = final_content\n            if not rendered_stream:\n                console.print(Panel(Markdown(final_content), title=\"Coder\", border_style=\"magenta\", box=box.ROUNDED))\n            break\n\n        # Record assistant message with tool calls\n        coder_history.append({\n            \"role\": \"assistant\",\n            \"content\": reply.content,\n            \"tool_calls\": [tc.model_dump() for tc in tool_calls],\n        })\n\n        # Execute tool calls one by one\n        for tool_call in tool_calls:\n            tool_name = tool_call.function.name\n            args = json.loads(tool_call.function.arguments)\n\n            if tool_name == \"write_file\":\n                result = write_file(**args)\n                path = args.get(\"path\")\n                if path:\n                    log_created_files([path], created_files_session)\n\n            elif tool_name == \"write_files\":\n                result = write_files(**args)\n                files = args.get(\"files\") or []\n                paths = [f.get(\"path\") for f in files if f.get(\"path\")]\n                log_created_files(paths, created_files_session)\n\n            elif tool_name == \"run_shell_command\":\n                command = args.get(\"command\")\n                user_input_val = args.get(\"user_input\")\n                result = run_shell_command(command=command, user_input=user_input_val)\n                if command:\n                    log_command_run(command, commands_session)\n\n            elif tool_name == \"edit_file\":\n                path = args.get(\"path\")\n                before_text = _read_file_text(path) if path else None\n                result = edit_file(**args)\n                after_text = _read_file_text(path) if path else None\n                mode = args.get(\"mode\", \"append\")\n                if path:\n                    log_edited_file(path, mode, edited_files_session)\n                    render_edit_diff(path, before_text, after_text)\n\n            elif tool_name == \"read_file\":\n                result = read_file(**args)\n\n            elif tool_name == \"read_files\":\n                result = read_files(**args)\n\n            elif tool_name == \"run_python_file\":\n                result = run_python_file(**args)\n                path = args.get(\"path\")\n                if path:\n                    log_command_run(f\"python3 {path}\", commands_session)\n\n            elif tool_name == \"run_code_file\":\n                result = run_code_file(**args)\n                path = args.get(\"path\")\n                if path:\n                    log_command_run(f\"run_code_file {path}\", commands_session)\n\n            elif tool_name == \"generate_project_structure\":\n                result = generate_project_structure(**args)\n                folder = args.get(\"folder_name\", \"\")\n                files = args.get(\"files\") or []\n                paths = [os.path.join(folder, f.get(\"path\")) for f in files if f.get(\"path\")]\n                log_created_files(paths, created_files_session)\n            else:\n                result = f\"‚ö†Ô∏è Unknown tool: {tool_name}\"\n\n            # Feed tool result back into coder history\n            coder_history.append({\n                \"role\": \"tool\",\n                \"tool_call_id\": tool_call.id,\n                \"content\": str(result),\n            })\n    else:\n        console.print(\"[bold red]‚ö†Ô∏è Coder: Max iterations reached. Stopping.[/bold red]\")\n\n    # ---------- Reviewer (optional fixes) ----------\n    has_file_changes = bool(created_files_session or edited_files_session)\n    review_notes: str | None = None\n    if has_file_changes:\n        # Build compact context of changed files\n        parts: list[str] = []\n        for path in created_files_session:\n            content = _read_file_text(path) or \"(empty or unreadable)\"\n            parts.append(f\"### Created: {path}\\n\\n```\\n{content}\\n```\\n\")\n        for path, _mode in edited_files_session:\n            content = _read_file_text(path) or \"(empty or unreadable)\"\n            parts.append(f\"### Edited: {path}\\n\\n```\\n{content}\\n```\\n\")\n        changed_context = \"\\n\\n\".join(parts)\n\n        reviewer_history = [\n            {\"role\": \"system\", \"content\": REVIEWER_PROMPT},\n            {\"role\": \"user\", \"content\": (\n                \"Please review the following changes for correctness, potential bugs, and improvements. \"\n                \"If trivial fixes are needed, you may apply them using the edit tools.\\n\\n\" + changed_context\n            )},\n        ]\n\n        for _ in range(8):\n            response, rendered_stream = _chat_stream(\n                messages=reviewer_history,\n                tools=tools,\n                tool_choice=\"auto\",\n                model=AZURE_OAI_DEPLOYMENT,\n                panel_title=\"Reviewer\",\n                panel_border_style=\"yellow\",\n            )\n            if response is None:\n                console.print(\"[bold red]Stopping reviewer due to connection error.[/bold red]\")\n                break\n            reply = response.choices[0].message\n            tool_calls = reply.tool_calls\n\n            if not tool_calls:\n                review_notes = reply.content or \"(No review notes)\"\n                if not rendered_stream:\n                    console.print(Panel(Markdown(review_notes), title=\"Reviewer\", border_style=\"yellow\", box=box.ROUNDED))\n                break\n\n            reviewer_history.append({\n                \"role\": \"assistant\",\n                \"content\": reply.content,\n                \"tool_calls\": [tc.model_dump() for tc in tool_calls],\n            })\n\n            for tool_call in tool_calls:\n                tool_name = tool_call.function.name\n                args = json.loads(tool_call.function.arguments)\n\n                if tool_name == \"edit_file\":\n                    path = args.get(\"path\")\n                    before_text = _read_file_text(path) if path else None\n                    result = edit_file(**args)\n                    after_text = _read_file_text(path) if path else None\n                    mode = args.get(\"mode\", \"append\")\n                    if path:\n                        log_edited_file(path, mode, edited_files_session)\n                        render_edit_diff(path, before_text, after_text)\n                elif tool_name == \"write_file\":\n                    result = write_file(**args)\n                    path = args.get(\"path\")\n                    if path:\n                        log_created_files([path], created_files_session)\n                elif tool_name == \"write_files\":\n                    result = write_files(**args)\n                    files = args.get(\"files\") or []\n                    paths = [f.get(\"path\") for f in files if f.get(\"path\")]\n                    log_created_files(paths, created_files_session)\n                elif tool_name == \"read_file\":\n                    result = read_file(**args)\n                elif tool_name == \"read_files\":\n                    result = read_files(**args)\n                elif tool_name == \"run_shell_command\":\n                    command = args.get(\"command\")\n                    user_input_val = args.get(\"user_input\")\n                    result = run_shell_command(command=command, user_input=user_input_val)\n                    if command:\n                        log_command_run(command, commands_session)\n                elif tool_name == \"run_python_file\":\n                    result = run_python_file(**args)\n                    path = args.get(\"path\")\n                    if path:\n                        log_command_run(f\"python3 {path}\", commands_session)\n                elif tool_name == \"run_code_file\":\n                    result = run_code_file(**args)\n                    path = args.get(\"path\")\n                    if path:\n                        log_command_run(f\"run_code_file {path}\", commands_session)\n                elif tool_name == \"generate_project_structure\":\n                    result = generate_project_structure(**args)\n                    folder = args.get(\"folder_name\", \"\")\n                    files = args.get(\"files\") or []\n                    paths = [os.path.join(folder, f.get(\"path\")) for f in files if f.get(\"path\")]\n                    log_created_files(paths, created_files_session)\n                else:\n                    result = f\"‚ö†Ô∏è Unknown tool: {tool_name}\"\n\n                reviewer_history.append({\n                    \"role\": \"tool\",\n                    \"tool_call_id\": tool_call.id,\n                    \"content\": str(result),\n                })\n        else:\n            console.print(\"[bold red]‚ö†Ô∏è Reviewer: Max iterations reached. Stopping.[/bold red]\")\n\n    # ---------- Final summary ----------\n    has_file_changes = bool(created_files_session or edited_files_session)\n    if has_file_changes:\n        _render_summary(created_files_session, edited_files_session, commands_session, None)\n    else:\n        # No file changes; nothing to summarize\n        pass\n\n# Initial system prompt (added lazily when starting a fresh session)\nSYSTEM_PROMPT = (\n    \"\"\"\nYou are an AI Software Engineer working inside an AI-powered IDE.\n\nYour job is to take high-level goals from the user (e.g., \"Build a CLI todo app\") and fully complete them using the available tools.\n\nYou are not just a code generator ‚Äî you think, plan, verify, fix, and iterate to accomplish the goal end-to-end.\n\n## Responsibilities\n\n1. **Understand the Goal**  \n   Carefully read the user's message to understand the desired outcome.\n\n2. **Plan the Task**  \n   Use the `plan_task` tool to break the goal into smaller actionable steps (like \"write main.py\", \"define CLI\", etc.)\n\n3. **Generate Project Structure**  \n   If a project folder needs to be created with multiple files, use the `generate_project_structure` tool.\n\n4. **Execute Step-by-Step**  \n   For individual tasks, use `write_file`, `read_file`, `edit_file`, `run_code_file`, and `run_shell_command`.\n\n5. **Verify and Self-Debug**  \n   Always run generated code; debug and iterate on failures.\n\n6. **Stay Autonomous**  \n   Don‚Äôt ask for permission at every step; only ask if user input is required.\n\n7. **Suggest the Next Move**  \n   After each step, clearly suggest the next logical move to complete the goal.\n\"\"\"\n)\n\n# Main loop\ndef run_repl_loop():\n    _print_header()\n    # Add system prompt only if starting fresh (no prior messages).\n    if history is not None and len(history.get()) == 0:\n        history.add(\"system\", SYSTEM_PROMPT)\n    _print_session_info()\n    # PromptSession with dynamic slash completion\n    session = PromptSession(completer=SlashCompleter(), bottom_toolbar=_bottom_toolbar)\n    while True:\n        try:\n            with patch_stdout():\n                user_input = session.prompt(\"\\nüí¨ You: \", complete_while_typing=True)\n        except (EOFError, KeyboardInterrupt):\n            break\n        if user_input.strip().lower() in [\"exit\", \"quit\"]:\n            break\n\n        # Step 1: Add user input to history\n        # Slash commands are handled locally and are NOT sent to the model\n        if _handle_slash_command(user_input):\n            # Already handled; do not send to LLM or record as normal message\n            continue\n\n        # Otherwise, record in session history and proceed\n        # Extract @paths and attach them as a tool-context message\n        cleaned_input, at_paths = _extract_at_paths(user_input)\n        if at_paths:\n            files = _expand_paths(at_paths)\n            if files:\n                tool_msg = _build_context_tool_message(files)\n                history.add(\"tool\", tool_msg.get(\"content\", \"\"))\n        history.add(\"user\", cleaned_input if cleaned_input else user_input)\n\n        # Step 2: Agent loop (LLM can call tools repeatedly until it's satisfied)\n        created_files_session: list[str] = []\n        edited_files_session: list[tuple[str, str]] = []\n        commands_session: list[str] = []\n        final_notes: str | None = None\n        for iteration in range(10):  # max 10 steps to prevent infinite loops\n            response, rendered_stream = _chat_stream(\n                messages=history.get(), tools=tools, tool_choice=\"auto\", model=AZURE_OAI_DEPLOYMENT\n            )\n            if response is None:\n                console.print(\"[bold red]Stopping due to connection error.[/bold red]\")\n                break\n\n            reply = response.choices[0].message\n            tool_calls = reply.tool_calls\n\n            # Step 3: No tool call ‚Äî LLM is done\n            if not tool_calls:\n                final_content = reply.content or \"(No reply)\"\n                final_notes = final_content\n                history.add(\"assistant\", final_content)\n                # Only show the summary if files were created or edited; otherwise show normal AI text\n                has_file_changes = bool(created_files_session or edited_files_session)\n                if has_file_changes:\n                    _render_summary(created_files_session, edited_files_session, commands_session, final_notes)\n                else:\n                    # If we already rendered the streamed content, do not re-print\n                    if not rendered_stream:\n                        console.print(_panel_for(\"assistant\", final_content))\n                break\n\n            # Step 4: Tool calls present, execute them\n            history.messages.append({\n                \"role\": \"assistant\",\n                \"content\": reply.content,  # may be None, that‚Äôs fine\n                \"tool_calls\": [tool_call.model_dump() for tool_call in reply.tool_calls]\n            })\n            \n            for tool_call in tool_calls:\n                tool_name = tool_call.function.name\n                args = json.loads(tool_call.function.arguments)\n\n                # Match the tool name and run accordingly\n                if tool_name == \"write_file\":\n                    result = write_file(**args)\n                    # Minimal UI: show created file\n                    path = args.get(\"path\")\n                    if path:\n                        log_created_files([path], created_files_session)\n\n                elif tool_name == \"write_files\":\n                    result = write_files(**args)\n                    # Minimal UI: show all created files (by intent)\n                    files = args.get(\"files\") or []\n                    paths = [f.get(\"path\") for f in files if f.get(\"path\")]\n                    log_created_files(paths, created_files_session)\n\n                elif tool_name == \"run_shell_command\":\n                    command = args.get(\"command\")\n                    user_input_val = args.get(\"user_input\")  # optional\n                    result = run_shell_command(command=command, user_input=user_input_val)\n                    if command:\n                        log_command_run(command, commands_session)\n\n                elif tool_name == \"edit_file\":\n                    # Capture before/after to render a diff\n                    path = args.get(\"path\")\n                    before_text = _read_file_text(path) if path else None\n                    result = edit_file(**args)\n                    after_text = _read_file_text(path) if path else None\n                    mode = args.get(\"mode\", \"append\")\n                    if path:\n                        log_edited_file(path, mode, edited_files_session)\n                        render_edit_diff(path, before_text, after_text)\n\n                elif tool_name == \"read_file\":\n                    result = read_file(**args)\n                    # Minimal UI: do not show reads\n\n                elif tool_name == \"read_files\":\n                    result = read_files(**args)\n                    # Minimal UI: do not show reads\n                \n                elif tool_name == \"run_python_file\":\n                    result = run_python_file(**args)\n                    path = args.get(\"path\")\n                    if path:\n                        log_command_run(f\"python3 {path}\", commands_session)\n                \n                elif tool_name == \"run_code_file\":\n                    result = run_code_file(**args)\n                    path = args.get(\"path\")\n                    if path:\n                        log_command_run(f\"run_code_file {path}\", commands_session)\n\n                elif tool_name == \"generate_project_structure\":\n                    result = generate_project_structure(**args)\n                    folder = args.get(\"folder_name\", \"\")\n                    files = args.get(\"files\") or []\n                    paths = [os.path.join(folder, f.get(\"path\")) for f in files if f.get(\"path\")]\n                    log_created_files(paths, created_files_session)\n                else:\n                    result = f\"‚ö†Ô∏è Unknown tool: {tool_name}\"\n\n                # Step 5: Add tool result back to chat history\n                history.messages.append({\n                    \"role\": \"tool\",\n                    \"tool_call_id\": tool_call.id,\n                    \"content\": str(result)\n                })\n        else:\n            console.print(\"[bold red]‚ö†Ô∏è Max iterations reached. Stopping.[/bold red]\")\n            # Only show the summary if files were created or edited; otherwise show normal AI text (if any)\n            has_file_changes = bool(created_files_session or edited_files_session)\n            if has_file_changes:\n                _render_summary(created_files_session, edited_files_session, commands_session, final_notes)\n            elif final_notes:\n                console.print(_panel_for(\"assistant\", final_notes))\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"AI IDE ‚Äî Agent REPL / Multi-agent CLI\")\n    parser.add_argument(\"--multi\", action=\"store_true\", help=\"Run in multi-agent mode (Planner -> Coder -> Reviewer)\")\n    parser.add_argument(\"--goal\", type=str, default=None, help=\"High-level goal for multi-agent mode\")\n    parser.add_argument(\"--session\", type=str, default=None, help=\"Resume a specific session ID (from .sessions)\")\n    parser.add_argument(\"--new-session\", action=\"store_true\", help=\"Start a brand new session with a fresh ID\")\n    parser.add_argument(\"--sessions-dir\", type=str, default=\".sessions\", help=\"Directory to store session JSONL files\")\n    args = parser.parse_args()\n\n    # Initialize chat memory session\n    global history\n    if args.new_session:\n        history = ChatMemory.new_session(storage_dir=args.sessions_dir)\n    elif args.session:\n        history = ChatMemory.load(args.session, storage_dir=args.sessions_dir)\n    else:\n        history = ChatMemory(storage_dir=args.sessions_dir)\n\n    if args.multi:\n        if not args.goal:\n            console.print(\"[bold red]Please provide --goal for multi-agent mode.[/bold red]\")\n            return\n        _print_header()\n        run_multi_agent_session(args.goal)\n    else:\n        run_repl_loop()\n\n\nif __name__ == \"__main__\":\n    main()", "ts": 1755453291.0042815}
{"role": "user", "content": "@main.py", "ts": 1755453291.005001}
{"role": "user", "content": "", "ts": 1755453299.6337392}
